{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = 'https://rospotrebnadzor.ru'\n",
    "START_NUM = 1\n",
    "END_NUM = 70 \n",
    "# Первое упоминание о коронавирусе: \"О случаях заболевания пневмонией в Китайской Народной Республике\" (31 декабря 2019 г.)\n",
    "# На 12.11.2020 оно на 70-й странице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(article_url):\n",
    "    try:\n",
    "        article = requests.get(article_url)\n",
    "        article_soup = BeautifulSoup(article.text)\n",
    "        news_title = article_soup.find('h1')\n",
    "        news_detail = article_soup.find_all('div', class_='news-detail')\n",
    "        news_date = article_soup.find_all('p', class_='date')\n",
    "        output = [news_title.text, news_date[0].text, news_detail[0].text]\n",
    "    except:\n",
    "        output = ['SOMETHING_WRONG_WITH_ARTICLE', sys.exc_info()]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pprint(all_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "all_blocks = {}\n",
    "for i in range(START_NUM, END_NUM+1):\n",
    "    try:\n",
    "        time.sleep(0.300)\n",
    "        articles_block = {}\n",
    "        page_url = HOME + '/about/info/news/?PAGEN_1=' + str(i)\n",
    "        page = requests.get(page_url)\n",
    "        page_soup = BeautifulSoup(page.text, 'lxml')\n",
    "        all_urls = [HOME + href['href'] for href in page_soup.find_all(href=re.compile('news_details'))]\n",
    "        for article_url in all_urls:\n",
    "            element_id = article_url.split(\"ELEMENT_ID=\")[1]\n",
    "            articles_block[element_id] = get_article(article_url)\n",
    "        all_blocks[str(i)] = articles_block\n",
    "        print(\"Block \" + str(i) + \"\\tDone\")\n",
    "    except:\n",
    "        all_blocks[str(i)] = ['SOMETHING_WROND_WITH_BLOCK', sys.exc_info()]\n",
    "        print(\"Block \" + str(i) + \"\\tError\")\n",
    "        \n",
    "total_time = time.time()-start\n",
    "print(\"Total time \" + str(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open('all_blocks.json', 'w') as outfile:\n",
    "#    json.dump(all_blocks, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('all_blocks.pickle', 'wb') as f:\n",
    "#    pickle.dump(all_blocks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = {}\n",
    "for block in all_blocks.keys():\n",
    "    all_articles.update(all_blocks[block])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open('all_articles.pickle', 'wb') as f:\n",
    "#    pickle.dump(all_articles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "#with open('all_articles.json', 'w') as outfile:\n",
    "#    json.dump(all_articles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = [a[0] for a in all_articles.values()]\n",
    "all_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_titles = [title for title in all_titles if re.findall(r\"коронавирус\", title)]\n",
    "len(corona_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_num_articles = {}\n",
    "for element_id in all_articles.keys():\n",
    "    title = all_articles[element_id][0]\n",
    "    if re.findall(r\"COVID-2019\", title):\n",
    "        corona_num_articles[element_id] = all_articles[element_id]\n",
    "len(corona_num_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_num_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_num_dates = []\n",
    "for element_id in corona_num_articles.keys():\n",
    "    article_date = corona_num_articles[element_id][1]\n",
    "    article_date = re.sub(r\"[^0-9|\\.]\", \"\", article_date)\n",
    "    article_date = re.sub(r\"\\.$\", \"\", article_date)\n",
    "    article_date = datetime.strptime(article_date, '%d.%m.%Y').strftime(\"%Y-%m-%d\")\n",
    "    corona_num_dates.append(article_date)\n",
    "corona_num_dates    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ищем потенциальные пробелы в сообщениях. Пока они есть в начале марта и почему-то 19-го августа 2020. \n",
    "# На сайте Роспотребнадзора данных по РФ за эти периоды нет\n",
    "gaps = []\n",
    "for i in range(1, len(corona_num_dates)):\n",
    "    date_1 = corona_num_dates[i-1]\n",
    "    date_2 = corona_num_dates[i]\n",
    "    datediff = datetime.strptime(date_1, '%d.%m.%Y') - datetime.strptime(date_2, '%d.%m.%Y')\n",
    "    \n",
    "    if datediff.days != 1:\n",
    "        gaps.append((date_1, date_2))\n",
    "gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Обработаем начерно, просто удаляя ненужные части строк по паттернам\n",
    "corona_nums = []\n",
    "for element_id in corona_num_articles.keys():\n",
    "    corona_text = corona_num_articles[element_id][2]\n",
    "    corona_text = re.sub(r\"\\n\\n\", r\"\\n\", corona_text)\n",
    "    corona_first_sent = corona_text.split('\\n')[2]\n",
    "    corona_num = re.sub(r\"[\\xa0]+\", \"\", corona_first_sent)\n",
    "    corona_num = re.sub(r\"За последние сутки в России \", \"\", corona_num)\n",
    "    corona_num = re.sub(r\"зарегистрировано подтвержденных случаев коронавирусной инфекции COVID-19 – \", \"\", corona_num)\n",
    "    corona_num = re.sub(r\"в \\d\\d регион\", \"\", corona_num)\n",
    "    corona_num = re.sub(r\"в \\d регион\", \"\", corona_num)\n",
    "    corona_num = re.sub(r\"COVID-19\", \"\", corona_num)\n",
    "    corona_num = re.sub(r\"COVID-2019\", \"\", corona_num)\n",
    "    corona_num = corona_num.split(\"Российской Федерации\")[0]\n",
    "    corona_num = re.sub(r\"5 марта подтвержден завозной из Италии случай\", \"1\", corona_num)\n",
    "    corona_num = re.sub(r\"2 марта подтвержден завозной из Италии случай\", \"1\", corona_num)\n",
    "    corona_num = re.sub(r\"[^0-9]\", \"\", corona_num)\n",
    "    corona_nums.append(corona_num)\n",
    "#corona_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df = pd.DataFrame(list(zip(corona_num_dates, corona_nums)),\n",
    "                         columns =['Date', 'ConfirmedCases'])\n",
    "corona_df.to_csv('CoronaDF.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_num_articles = {}\n",
    "for element_id in all_articles.keys():\n",
    "    title = all_articles[element_id][0]\n",
    "    if re.findall(r\"бюллетень\", title):\n",
    "        tests_num_articles[element_id] = all_articles[element_id]\n",
    "len(tests_num_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! Даты идут со сдвигом на день. 5-го октября выкладывают даты от тестах за 4-е. \n",
    "\n",
    "tests_num_dates = []\n",
    "for element_id in tests_num_articles.keys():\n",
    "    article_date = tests_num_articles[element_id][1]\n",
    "    article_date = re.sub(r\"[^0-9|\\.]\", \"\", article_date)\n",
    "    article_date = re.sub(r\"\\.$\", \"\", article_date)\n",
    "    article_date = datetime.strptime(article_date, '%d.%m.%Y').strftime(\"%Y-%m-%d\")\n",
    "    tests_num_dates.append(article_date)\n",
    "len(tests_num_dates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"проведено 66 710 463 лабораторных исследования\"\n",
    "re.search(r'провед(.*?)исслед', s).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# просто ищем по паттерну\n",
    "tests_nums = []\n",
    "for element_id in tests_num_articles.keys():\n",
    "    tests_num = tests_num_articles[element_id][2]\n",
    "    tests_num = [x.group() for x in re.finditer( r'провед(.*?)исслед', tests_num)]\n",
    "    if len(tests_num) == 1:\n",
    "        tests_num = tests_num[0]\n",
    "    elif tests_num:\n",
    "        tests_num = tests_num[1]\n",
    "    else:\n",
    "        tests_num = ''\n",
    "    tests_num = re.sub(r\"[^0-9]\", \"\", tests_num)\n",
    "    tests_nums.append(tests_num)\n",
    "tests_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Даты идут со сдвигом на день. 5-го октября выкладывают даты от тестах за 4-е. \n",
    "corona_tests_df = pd.DataFrame(list(zip(tests_num_dates, tests_nums)),\n",
    "                         columns =['Date', 'TestsPerformed'])\n",
    "corona_tests_df.to_csv('CoronaTestsDF.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
